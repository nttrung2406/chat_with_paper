# Chat_with_paper
A RAG application for q&amp;a with paper

**Tech stack:**

1. Core AI (LLM for RAG)

âœ… LLaVA (LLaMA + Vision Adapter) â€“ Handles text + images/tables.

âœ… Quantized versions (GGUF with llama.cpp) â€“ Makes inference lightweight and runs on consumer GPUs/CPUs.

ðŸ’¡ Inference Engine: Use llama.cpp for ultra-lightweight deployment.

2. PDF Processing
   
âœ… PyMuPDF

âœ… PaddleOCR

4. Vector Search (Hybrid Search)
   
âœ… Milvus (Lite Mode)

6. Backend & Model Serving
   
âœ… FastAPI â€“ Handles async requests efficiently.

âœ… llama.cpp

8. Monitoring & Logging
   
âœ… Prometheus â€“ Tracks system metrics (RAM, GPU, API requests, etc.).

âœ… Grafana â€“ Visualizes logs and performance.
